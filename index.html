<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>My Master Presentation</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/white.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- My css -->
		<link rel="stylesheet" href="css/main.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Hybrid method for imbalanced datasets</h1>
					<br>
					<br>
					<p>Tianxiang Gao</p>
					<p>
						<small>April 17, 2015</a></small>
					</p>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li class="fragment highlight-blue">Motivation</li>
						<li>Introduction</li>
						<li>Methodology</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<!-- Example of nested vertical slides -->

				<section>
					<section>
						<h2>Motivation</h2>
						<p>“Learning from Imbalanced Data Sets,” <a href="http://www.site.uottawa.ca/~nat/Workshop2000/workshop2000.html" target="_blank">Proc. Am. Assoc. for Artificial Intelligence (AAAI) Workshop</a>, N. Japkowicz, ed., 2000, (Technical Report WS-00-05).</p>
						<p>“Workshop Learning from Imbalanced Data Sets II,” <a href="https://www.site.uottawa.ca/~nat/Workshop2003/workshop2003.html" target="_blank">Proc. Int'l Conf. Machine Learning</a>, N.V. Chawla, N. Japkowicz, and A. Kolcz, eds., 2003.</p>
						<p>N.V. Chawla, N. Japkowicz, and A. Kolcz, “Editorial: Special Issue on Learning from Imbalanced Data Sets,” <a href="https://www.site.uottawa.ca/~nat/Research/explorations_cfp.html" target="_blank">ACM SIGKDD Explorations Newsletter</a>, vol. 6, no. 1, pp. 1-6, 2004.</p>
						<br>
					</section>
					<section>
						<h2>fraud/intrusion detection</h2>
						<p><img data-src="img/Credit-Card-Fraud.jpg"></p>
					</section>
					<section>
						<h2>Risk Management</h2>
						<p><img data-src="img/risk-management.png"></p>
					</section>
					<section>
						<h2>medical diagnosis/monitoring</h2>
						<p><img data-src="img/medical-diagnosis.jpg"></p>
					</section>
					<section>
						<h2>bioinformatics</h2>
						<p><img data-src="img/bioinformatics.jpg"></p>
					</section>
					<section>
						<h2>text categorization</h2>
						<p><img data-src="img/text-categorization.gif"></p>
					</section>
					<section>
						<h2>direct marketing</h2>
						<p><img data-src="img/direct-marketing.png"></p>
					</section>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li class="fragment highlight-blue">Introduction</li>
						<li>Methodology</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li><span style="color:#1b91ff;">Introduction </span>
							<ul>
								<li class="fragment highlight-blue">Classifier - Decision tree</li>
								<li>Assess metrics</li>
								<li>Nature of problem</li>
							</ul>
						</li>
						<li>Methodology</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<section>
						<h2>Classifier</h2>
						<p><strong>Classification problem</strong> is to assign a class label to previously unseen data based on learning from given data.</p>
						<p>Model to classify those data is called <strong>Classifier</strong>.</p>
					</section>

					<section>
						<h2>Dataset of Playing Tennis</h2>
						<table>
							<thead>
								<tr>
									<th>Outlook</th>
									<th>Temp.</th>
									<th>Humidity</th>
									<th>Windy</th>
									<th class="response-variable">Play</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Sunny</td>
									<td>Hot</td>
									<td>High</td>
									<td>False</td>
									<td class="response-variable">No</td>
								<tr>
								<tr>
									<td>Sunny</td>
									<td>Hot</td>
									<td>High</td>
									<td>True</td>
									<td class="response-variable">No</td>
								<tr>
								<tr>
									<td>Overcase</td>
									<td>Hot</td>
									<td>High</td>
									<td>False</td>
									<td class="response-variable">Yes</td>
								<tr>
								<tr>
									<td>...</td>
									<td>...</td>
									<td>...</td>
									<td>...</td>
									<td class="response-variable">...</td>
								<tr>
								<tr>
									<td>Rainy</td>
									<td>Mild</td>
									<td>High</td>
									<td>True</td>
									<td class="response-variable">No</td>
								<tr>
							</tbody>
						</table>
					</section>

					<section>
						<h2>Decision Tree</h2>
						<img height="550px" data-src="img/weather_example.png">
					</section>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li><span style="color:#1b91ff;">Introduction</span>
							<ul>
								<li>Classifier - Decision tree</li>
								<li class="fragment highlight-blue">Assess metric</li>
								<li>Nature of problem</li>
							</ul>
						</li>
						<li>Methodology</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Assess metric</h2>
					<table>
						<caption>Confusion Matrix</caption>
						<thead>
							<tr>
								<th></th>
								<th>Predicted +</th>
								<th>Predicted -</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<th>Actural +</th>
								<td>True Positive (TP)</td>
								<td>False Negative (FN)</td>
							<tr>
							<tr>
								<th>Actural -</th>
								<td>False Positive (FP)</td>
								<td>True Negative (TN)</td>
							<tr>
						</tbody>
					</table>
					<P>Cut-off value is <strong>0.5</strong></P>
				</section>

				<section>
					<h2>Assess metric</h2>
					<p>Accuracy = (TP + TN) / (TP + TN + FN + FP)</p>
				</section>

				<section>
					<h2>Assess metric</h2>
					<p>TPR = TP / (TP + FN)</p>
					<p>FPR = FP / (FP + TN)</p>
				</section>

				<section>
					<h2>ROC & AUC</h2>
					<img data-src="img/10thROC.png">
					<p>Cut-off values are from 0 to 1.</p>
				</section>

				<section>
					<h2>Class Balance Accuracy</h2>
					$CBA =\frac{\sum_{i=1}^{k} \frac{C_{ii}}{max(C_{i.}, C_{.i}) } }{k}$
					<p>where $C_{i.} = \sum_{j=1}^{k} C_{ij} $ and $C_{.i} = \sum_{i=1}^{k} C_{ji} $. </p>
					<p>Cut-off value is usually 0.5</p>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li><span style="color:#1b91ff;">Introduction</span>
							<ul>
								<li>Classifier - Decision tree</li>
								<li>Assess metric</li>
								<li class="fragment highlight-blue">Nature of problem</li>
							</ul>
						</li>
						<li>Methodology</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Nature of problem</h2>
					<img height="450px" data-src="img/problems.png">
					<p><span class="fragment">overlap,</span> <span class="fragment">within-class imbalance,</span> <span class="fragment"> disjunct rules.</span></p>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li class="fragment highlight-blue">Methodology</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li><span style="color:#1b91ff;">Methodology</span>
							<ul>
								<li class="fragment highlight-blue">Sampling</li>
								<li>Instance Selection</li>
								<li>Hybrid method of SMOTE and Selection</li>
							</ul>

						</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Sampling</h2>
					<ul>
						<li>Undersampling</li>
						<li>Oversampling</li>
						<li>SMOTE</li>
					</ul>
				</section>

				<section>
					<h2>Sampling</h2>
					<p>Undersampling beats oversampling since oversamping causes the decision boundary too specific.</p>
					<p>SMOTE is powerful method to improve the performance of classifiers by introducing synthetic minority samples.</p>
				</section>

				<section>
					<section>
						<h2>SMOTE</h2>
						<img data-src="img/alg/SMOTE.png" style="max-height:550px;">
					</section>

					<section>
						<h2>SMOTE</h2>
						<h4>tuning parameter</h4>
						<ul>
							<li>number of nearest neighbors</li>
							<li>percentage of oversampling minority class</li>
							<li>percentage of undersampling majority class</li>
						</ul>						
					</section>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li><span style="color:#1b91ff;">Methodology</span>
							<ul>
								<li>Sampling</li>
								<li class="fragment highlight-blue">Instance Selection</li>
								<li>Hybrid method of SMOTE and Selection</li>
							</ul>

						</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Instance Selection</h2>
					<p class="fragment">Selects subset of training dataset such that removes superfluous instances, maintain performances.
					</p>
				</section>

				<section>
					<h2> Wrapper and Filter</h2>
					<p class="fragment"><em>Wrapper</em> selects a subset of instances based on accuracy of a predefined classifier. 
					</p>
					<p class="fragment"><em>Filter</em> ranks instances through non-classifier based function and then select the instances from the ranking.</p>
				</section>

				<section>
					<h2> Greedy Selection</h2>
					<p><span class="fragment">Greedy selection is a two-steps wrapper method:</span> <span class="fragment">generates a number of candidate subsets,</span> <span class="fragment"> and starts with one candidate subset</span> <span class="fragment">and continuouly combines the other subsets if combining improves the performance of classifier.</span>
					</p>
				</section>

				<section>
					<section>
						<h2> Greedy Selection</h2>
						<p class="fragment"><img data-src="img/alg/instance_selection.png" style="max-height:550px;"></p>
					</section>

					<section>
						<h2>Greedy Selection</h2>
						<h4>tuning parameter</h4>
						<ul>
							<li>number of candidate subsets</li>
							<li>size of each subset</li>
						</ul>						
					</section>
				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li><span style="color:#1b91ff;">Methodology</span>
							<ul>
								<li>Sampling</li>
								<li>Instance Selection</li>
								<li class="fragment highlight-blue">Hybrid method of SMOTE and Selection</li>
							</ul>

						</li>
						<li>Experimental results</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Hybrid Method</h2>
					<p>Hyrid method is a combination method of SMOTE and greedy selection.</p>
					<p class="fragment">Firstly, SMOTEs the instances of minority class, and combines those synthetic instances with majority class.</p>
					<p class="fragment">Secondly, selects the optimum subset from the SMOTEd instances as the final training dataset.</p>
				</section>

				<section>
					<section>
						<h2> Hybrid Method</h2>
						<p class="fragment"><img data-src="img/alg/hybrid.png">
						</p>
					</section>

					<section>
						<h2> Hybrid Method</h2>
						<h4>tuning parameter</h4>
						<ul>
							<li>number of nearest neighbors</li>
							<li>percentage of oversampling</li>
							<li>percentage of undersampling</li>
							<li>number of candidate subsets</li>
							<li>size of each subset</li>
						</ul>
					</section>

				</section>

				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li>Methodology</li>
						<li><span style="color:#1b91ff;">Experimental results</span>
							<ul>
								<li class="fragment highlight-blue">Characteristics of Datasets</li>
								<li>SMOTEd Training Datasets</li>
								<li>Greedy-Selected Training Datasets</li>
								<li>Hybrid-Selected Trianing Datasets</li>
							</ul>
						</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>

				<section>
					<h2>Characteristics of Datasets</h2>
					<p>4 well-known imbalanced datasets in UCI, and one medical dataset</p>
					<img data-src="img/data.png" class="fragment">
				</section>

				<section>
				<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li>Methodology</li>
						<li><span style="color:#1b91ff;">Experimental results</span>
							<ul>
								<li>Characteristics of Datasets</li>
								<li class="fragment highlight-blue">SMOTEd Training Datasets</li>
								<li>Greedy-Selected Training Datasets</li>
								<li>Hybrid-Selected Trianing Datasets</li>
							</ul>
						</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>
				
				<section>
					<h2>SMOTE Training Datasets</h2>
					<h4 class="fragment">tuning parameters</h4>
						<ul class="fragment">
							<li>percentage of oversampling</li>
							<li>percentage of undersampling</li>
						</ul>
				</section>

				<section>
					<h2>percentage of undersampling</h2>
					<p class="fragment">The percentage of undersampling is not percentage of undersampling the entire majority class.</p>
					<p class="fragment">Instead, it is to maintain percentage of majority class with respective to SMOTEd minority class. In another word, it <strong>depends</strong> on percentage of oversampling minority class.</p>
					<p class="fragment">Artificially sets it to <strong>200%</strong>.</p>
					<p class="fragment"><strong>Note:</strong>if undersampling majority instances is more than its original training dataset, majority class would oversample with replacement.</p>
				</section>

				<section>
					<h2>percentage of oversampling</h2>
					<p class="fragment">We implemented <em>10-fold cross validation</em> to select the optimum percentage of oversampling among 100% to 1000%.</p>
					<p class="fragment">We used both accuracy and Area Under Curve (AUC) as assess metric to evaluate performances.</p>
				</section>

				<section>
					<h2>percentage of oversampling</h2>
					<img class="fragment" data-src="img/10thROC.png">
				</section>

				<section>
					<h2>percentage of oversampling</h2>
					<img width="400" class="fragment" data-src="img/Acc.png" style="float:left;">
					<img width="400" class="fragment" data-src="img/AUC.png" style="float:right;">
				</section>

				<section>
					<h2>percentage of oversampling</h2>
					<img class="fragment" data-src="img/acc_auc.png">
					<p class="fragment">From the previous figures and this table, <strong>200%</strong> is the optimum oversampling percentage for <em>yearst5</em> dataset since it has best AUC, competitive accuracy, and simpler.</p>
				</section>

				<section>
					<h2>percentage of oversampling</h2>
					<p>Based on the strategy, the best optimum setting for each dataset is listed in the table.</p>
					<img class="fragment" data-src="img/best_smote.png">
				</section>

				<section>
				<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li>Methodology</li>
						<li><span style="color:#1b91ff;">Experimental results</span>
							<ul>
								<li>Characteristics of Datasets</li>
								<li>SMOTEd Training Datasets</li>
								<li class="fragment highlight-blue">Greedy-Selected Training Datasets</li>
								<li>Hybrid-Selected Trianing Datasets</li>
							</ul>
						</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>
				
				<section>
					<h2>Greedy Selection</h2>
					<h4 class="fragment">tuning parameters</h4>
						<ul class="fragment">
							<li>number of candidate subset</li>
							<li>size of each candiate subset</li>
						</ul>
				</section>

				<section>
					<h2>tuning parameters</h2>
					<p>Usually over 90 percent of time comsuming is to find approporate tuning parameters. It's not very efficient.</p>
					<p><span class="fragment">Instead, we simply divided a dataset into 100 parts.</span> <span class="fragment">Then, in each part, the size of subset has been fixed automatically.</span></p>
					<p class="fragment">The key is to choose an appropriate <strong>assess metric</strong>.</p>
				</section>

				
				<section>
					<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li>Methodology</li>
						<li><span style="color:#1b91ff;">Experimental results</span>
							<ul>
								<li>Characteristics of Datasets</li>
								<li>SMOTEd Training Datasets</li>
								<li>Greedy-Selected Training Datasets</li>
								<li class="fragment highlight-blue">Hybrid-Selected Trianing Datasets</li>
							</ul>
						</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>
					
				<section>
					<h2>Hybrid-Selected Trianing Datasets</h2>
					<h4 class="fragment">tuning parameters</h4>
						<ul class="fragment">
							<li>number of nearest neighbors</li>
							<li>percentage of oversampling</li>
							<li>percentage of undersampling</li>
							<li>number of candidate subsets</li>
							<li>size of each candidate subset</li>
						</ul>
				</section>
					
				<section>
					<h2>tuning parameters</h2>
					<p>Usually assigns <strong>5</strong> to number of nearest neighbors.</p>
					<p>Implement same strategy to set up the number of candidate subsets, and size of each candidate subset.</p>
					<p>Also use <strong>10-fold cross validation</strong> to choose the optimum sampling percentages.</p>
				</section>

				<section>
					<h2>tunning parameters</h2>
					<p>Based on the strategy, the best optimum setting for each dataset is listed in the table.</p>
					<img class="fragment" data-src="img/best_hybrid.png">
				</section>

				
				<section>
				<h2>Contents</h2>
					<ul>
						<li>Motivation</li>
						<li>Introduction</li>
						<li>Methodology</li>
						<li><span style="color:#1b91ff;">Experimental results</span>
							<ul>
								<li>Characteristics of Datasets</li>
								<li>SMOTEd Training Datasets</li>
								<li>Greedy-Selected Training Datasets</li>
								<li>Hybrid-Selected Trianing Datasets</li>
								<li class="fragment highlight-blue">Results</li>
							</ul>
						</li>
						<li>Conclusion and future research</li>
					</ul>
				</section>
					
				<section>	
					<section>
						<h2>Results</h2>
						<p class="fragment">Randomly select <strong>4/5</strong> of a dataset as original training dataset, and the rest is testing dataset.</p>
						<p class="fragment">Implement those strategies to preprocess the dataset and we got four different training datasets: <strong>Control, Greedy Selection, SMOTE, and Hybrid</strong>.</p>
						<p class="fragment">Fit those four different training datasets through regular <strong>decision tree</strong>.</p>
						<p class="fragment">Predict the fit onto the identical test dataset.</p>
						<p class="fragment">Process these steps over <strong>100</strong> times among each dataset. Then, evaluate predications through computing <strong>AUC, CBA, and accuracy</strong>.</p>
					</section>

					<section>
						<h2>Dataset: g7</h2>
						<h4 style="float:left;">CBA Assess Metric</h4>
						<h4 >AUC Assess Metric</h4>
						<img width="450" data-src="img/g7_cba.png" style="float:left;">
						<img width="450" data-src="img/g7_auc.png">	
					</section>

					<section>
						<h2>Dataset: seg1</h2>
						<h4 style="float:left;">CBA Assess Metric</h4>
						<h4 >AUC Assess Metric</h4>
						<img width="450" data-src="img/seg1_cba.png" style="float:left;">
						<img width="450" data-src="img/seg1_auc.png">	
					</section>

					<section>
						<h2>Dataset: car3</h2>
						<h4 style="float:left;">CBA Assess Metric</h4>
						<h4 >AUC Assess Metric</h4>
						<img width="450" data-src="img/car3_cba.png" style="float:left;">
						<img width="450" data-src="img/car3_auc.png">	
					</section>
					
					<section>
						<h2>Dataset: yeast5</h2>
						<h4 style="float:left;">CBA Assess Metric</h4>
						<h4 >AUC Assess Metric</h4>
						<img width="450" data-src="img/yeast5_cba.png" style="float:left;">
						<img width="450" data-src="img/yeast5_auc.png">	
					</section>

					<section>
						<h2>Dataset: medical</h2>
						<h4 style="float:left;">CBA Assess Metric</h4>
						<h4>AUC Assess Metric</h4>
						<img width="450" data-src="img/medical_cba.png" style="float:left;">
						<img width="450" data-src="img/medical_auc.png">	
					</section>
					
				</section>

				<section>
					<section>
						<h2>Contents</h2>
							<ul>
								<li>Motivation</li>
								<li>Introduction</li>
								<li>Methodology</li>
								<li>Experimental results</li>
								<li style="color:#1b91ff;">Conclusion and future research</li>
							</ul>
					</section>
					<section>
						<h2>Conclusion and future research</h2>
						<ul>
							<li>Hybrid method makes classifiers work better.</li>
							<li>Efficient and very fast.</li>
							<li>Flexible since it has varied settings.</li>
							<li>Selecting an appropriate assess metric is essential for wrapper-baseed method.</li>
							<li>Comprehensive assess metric is better.</li>
						</ul>
					</section>
				</section>

				<section style="text-align: left;">
					<h1>Questions?</h1>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'convex', // none/fade/slide/convex/concave/zoom

				// math

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/math/math.js', async: true }
				]

			});

		</script>

	</body>
</html>
